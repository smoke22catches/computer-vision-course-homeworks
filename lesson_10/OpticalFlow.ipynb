{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lucas-Kanade Optical Flow Detector\n",
    "\n",
    "In this notebook we demonstrate the use of optical flow detection based on [Lucas-Kanade algorithm](https://en.wikipedia.org/wiki/Lucas%E2%80%93Kanade_method). The algorithm is conceptually very similar to the Harris corner detector with the addition of the temporal luminance gradient. Optical flow helps us to estimate motion on a video and, as a consequence, it allows us to track keypoints across the video frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [15, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialisation\n",
    "\n",
    "We will use the Shi-Tomasi corner detector which is an enhanced variant of the famous Harris detector. You can learn more about the Shi-Tomasi detector by reading the original [paper](https://users.cs.duke.edu/~tomasi/papers/shi/TR_93-1399_Cornell.pdf) or having a look at the very comprehensible OpenCV [tutorial](https://docs.opencv.org/3.4/d4/d8c/tutorial_py_shi_tomasi.html). The video used in this notebook can be found [here]( https://www.bogotobogo.com/python/OpenCV_Python/images/mean_shift_tracking/slow_traffic_small.mp4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = cv2.VideoCapture('data/slow_traffic_small.mp4')\n",
    "\n",
    "# ShiTomasi corner detection\n",
    "config_st = {'maxCorners': 100,\n",
    "             'qualityLevel': 0.3,\n",
    "             'minDistance': 7,\n",
    "             'blockSize': 7}\n",
    "\n",
    "# Lucas-Kanade optical flow\n",
    "config_lk = {'winSize': (15, 15),\n",
    "             'maxLevel': 2,\n",
    "             'criteria': (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Initial Keypoints to Track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some random colors\n",
    "color = np.random.randint(0, 255, (100, 3))\n",
    "\n",
    "# Take first frame and find keypoints\n",
    "ret, source = video.read()\n",
    "assert ret\n",
    "\n",
    "src_gray = cv2.cvtColor(source, cv2.COLOR_BGR2GRAY)\n",
    "p_src = cv2.goodFeaturesToTrack(src_gray, mask=None, **config_st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to better illustrate the optical flow detector in work, we will not apply in a frame by frame basis. Instead, we \"fast forward\" the video by several milliseconds so the perceived motion is larger. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fast forward by 40 frames\n",
    "for _ in range(40):\n",
    "    ret, frame = video.read()\n",
    "    assert ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate Optical Flow\n",
    "\n",
    "We will now use the Lucas-Kanade algorithm to estimate the optical flow between two frames. We will also print the results on the frame in order to better illustrate the meaning of optical flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read next frame\n",
    "ret, target = video.read()    \n",
    "dst_gray = cv2.cvtColor(target, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Calculate optical flow\n",
    "p_dst, status, err = cv2.calcOpticalFlowPyrLK(src_gray, dst_gray, p_src, None, **config_lk)\n",
    "\n",
    "# Select points that have been successfully tracked\n",
    "if p_dst is not None:\n",
    "    p_dst = p_dst[status==1]\n",
    "    p_src = p_src[status==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now draw the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty mask image for drawing purposes\n",
    "mask = np.zeros_like(source)\n",
    "    \n",
    "# Draw the tracks\n",
    "for i, (dst, src) in enumerate(zip(p_dst, p_src)):\n",
    "    x_dst, y_dst = dst\n",
    "    x_src, y_src = src\n",
    "    \n",
    "    mask = cv2.arrowedLine(mask, (int(x_src), int(y_src)), (int(x_dst), int(y_dst)),\n",
    "                           color[i].tolist(), 2, tipLength=0.5)    \n",
    "    target = cv2.circle(target, (int(x_src), int(y_src)), 5, color[i].tolist(), -1)\n",
    "\n",
    "result = cv2.add(target, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(121), plt.imshow(cv2.cvtColor(source, cv2.COLOR_BGR2RGB)), plt.title('Source')\n",
    "plt.subplot(122), plt.imshow(cv2.cvtColor(result, cv2.COLOR_BGR2RGB)), plt.title('Target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compound = cv2.addWeighted(result, 0.75, source, 0.25, gamma=0)\n",
    "plt.imshow(cv2.cvtColor(compound, cv2.COLOR_BGR2RGB))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
